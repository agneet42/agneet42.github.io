<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Agneet Chatterjee</title>

  <meta name="author" content="Agneet Chatterjee">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Agneet Chatterjee</name>
              </p>
              <p>I am a  2nd year PhD student at Arizona State University, where I work at the intersection of computer vision and natural language processing. I am fortunate to be advised by <a href="https://www.public.asu.edu/~cbaral/">Chitta Baral</a> and <a href="https://yezhouyang.engineering.asu.edu/">Yezhou Yang</a>.
              </p>
              <p>
                I received my Bachelors in Computer Science from <a href="http://www.jaduniv.edu.in/">Jadavpur University</a> in 2019, where I worked with 
                <a href="http://www.jaduniv.edu.in/profile.php?uid=686">Ram Sarkar</a> , 
                <a href="https://sites.google.com/site/sarbaniroy/">Sarbani Roy</a> & 
                <a href="https://sites.google.com/site/drujjwalmaulik/">Ujjwal Maulik</a>.
              </p>
              <p>
                I spent 3 years as a software engineer at <a href="https://www.salesforce.com/in/?ir=1">Salesforce</a>, working in the Quote to Cash domain.  
                I also researched at the  <a href="https://cnerg-iitkgp.github.io/">CNeRG Lab</a> with <a href="http://www.facweb.iitkgp.ac.in/~niloy/">Niloy Ganguly</a>, dabbling on social and spatio-temporal graphs.  
                I was an intern at <a href="https://research.samsung.com/sri-b/">Samsung Research India</a>  developing physically based renderers.
              </p>
              <p style="text-align:center">
                <a href="mailto:agneet@asu.edu">Email</a> &nbsp/&nbsp
                <a href="data/agneet_phd_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=RGRaOegAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/agneet42">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/agneet42/">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/agneet_profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/agneet_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I investigate and improve spatial reasoning abilities in text-to-image and multimodal large language models. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:%;vertical-align:middle">
              <img src="images/lang_depth.png" alt="prl" width="384" height="226.4">
            </td>
            
            
            <td width="75%" valign="middle">
              <span class="papertitle">On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation</span>
              <br>
              <strong>Agneet Chatterjee</strong>, <a href="https://www.tejasgokhale.com/">Tejas Gokhale</a>, <a href="https://www.public.asu.edu/~cbaral/">Chitta Baral</a>,  <a href="https://yezhouyang.engineering.asu.edu/">Yezhou Yang</a>
              <br>
              <em>CVPR  2024</em>
              <br>
              <p> We analyze the impact of the language prior in guiding monocular depth estimation. Our findings indicate that language guided depth estimators benefit only with scene-level descriptions and counter-intuitively fare worse with low-level sentences that describe 3D spatial relationships. Moreover, we find that such methods are less robust to distribution shifts in comparison to vision-only methods. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lite.png" alt="prl" width="384" height="384">
            </td>
            
            
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2310.18581">
                <span class="papertitle">Accelerating LLM Inference by Enabling Intermediate Layer Decoding</span>
              </a>
              <br>
              <a href="https://nrjvarshney.github.io/">Neeraj Varshney</a>, <strong>Agneet Chatterjee</strong>, <a href="https://scholar.google.com/citations?user=2UPwJC4AAAAJ&hl=en">Mihir Parmar</a>, <a href="https://www.public.asu.edu/~cbaral/">Chitta Baral</a>
              <br>
              <em>NAACL 2024</em>
              <br>
              <p>Instruction tuning Large Language Models (LLMs) with additional explicit Losses from the InTermediate layErs (LITE) enables these layers to acquire <i>good</i> generation abilities; enabling efficient early exiting abilities, saving an average of 37.86% Floating Point Operations (FLOPs).</p>
            </td>
          </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                This website's source code is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">here</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>
</html>
